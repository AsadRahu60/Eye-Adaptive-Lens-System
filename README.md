<p align="center">
  <img src="assets/social-preview.png" alt="Eye ‚Äî Adaptive Lens System" width="100%">
</p>

# Eye ‚Äî Adaptive Lens System for Amblyopia (R&D Prototype)

> **Disclaimer:** Research/education prototype. **Not a medical device.** Do not use for self-treatment.

[![License: MIT](https://img.shields.io/badge/License-MIT-brightgreen.svg)](LICENSE)
[![CI](https://img.shields.io/github/actions/workflow/status/AsadRahu60/eye-adaptive-lens/ci.yml?label=CI)](https://github.com/AsadRahu60/eye-adaptive-lens/actions)
[![Code style: Black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Made with: ESP32 + Python](https://img.shields.io/badge/made%20with-ESP32%20%2B%20Python-blue)](https://www.espressif.com/en/products/socs/esp32-s3)
[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-success.svg)](CONTRIBUTING.md)

Electronically tunable **per-eye focus** + **LC shutter occlusion** for supervised amblyopia research tasks. Sensor-aware modes (near/desk/outdoor), **manual + automated therapy profiles**, and **QA-first** documentation (URS ‚Üí SRS ‚Üí RTM ‚Üí Tests).

---

## Table of Contents
- [Why](#why)
- [Architecture](#architecture)
- [Quality & Testing](#quality--testing)
- [Quick Start](#quick-start)
- [Project Layout](#project-layout)
- [Roadmap](#roadmap)
- [Hiring Manager Highlights](#hiring-manager-highlights)
- [Contributing](#contributing)
- [License](#license)

---

## Why
I grew up with amblyopia and want a treatment path that‚Äôs adaptive, comfortable, and measurable‚Äîso patients actually stick with it.**Amblyopia focus.** Amblyopia is a binocular imbalance‚Äîreduced acuity and suppression in one eye‚Äîthat‚Äôs often treated with static occlusion (patching), which can be hard to personalize and sustain. **Eye** provides a **programmable, supervised research instrument** to deliver **graded per-eye stimuli** (diopter ramps and LC occlusion) with strict safety guardrails and full telemetry. This supports experiments on **binocular balance**, comfort envelopes, and adherence‚Äîgenerating clean, reproducible logs for clinician-led protocols. *(R&D only ‚Äî not a medical device.)*
 
This repo is a research prototype to test whether safe, gradual per-eye focus changes plus transparent occlusion can improve adherence and outcomes, where as the traditional patching is static and hard to personalize. **Eye** explores dynamic, clinician-configurable training: subtle per-eye focus changes + intermittent occlusion, driven by context and fully logged.

### MVP Goals
- Per-eye focus control (Optotune/Varioptic) with smooth ramps
- Per-eye LC occlusion (AC drive, no DC bias)
- Sensors (ToF, ALS, IMU) ‚Üí context (near/desk/outdoor)
- BLE UI (manual sliders + profiles) and data logging

---

## Architecture
```mermaid
flowchart LR
  subgraph Optics
    LTL[Tunable Lens L]:::opt
    RTL[Tunable Lens R]:::opt
    LCSL[LC Shutter L]:::opt
    LCSR[LC Shutter R]:::opt
  end

  subgraph Control
    ESP[ESP32-S3\nSensors + BLE + LC drive]:::ctrl
    PI[Raspberry Pi 5\nPolicy + Logs + UI]:::ctrl
  end

  LTL <-. USB/UART .-> PI
  RTL <-. USB/UART .-> PI
  LCSL <-- PWM AC --> ESP
  LCSR <-- PWM AC --> ESP
  ESP <-- I2C --> SENSORS[VL53L1X + TSL2591 + BNO055]:::sens
  PI <-- BLE / Wi-Fi --> APP[Mobile / Web UI]:::ui

  classDef opt fill:#f6ffed,stroke:#47c73b;
  classDef ctrl fill:#eef7ff,stroke:#2f6feb;
  classDef sens fill:#fff6e6,stroke:#e59f00;
  classDef ui fill:#f3e8ff,stroke:#7c3aed;

```

**Stack:** ESP32‚ÄëS3 (Arduino), Python 3 host, BLE GATT, I¬≤C sensors, H‚Äëbridge for LC shutters, Optotune/Varioptic lens drivers, optional Flutter app.

---

## Vision Therapy Simulator (Computer Vision)

To enable rapid experimentation when physical tunable lens hardware is unavailable,
this project includes a **computer-vision-based simulation module** located at:

‚û°Ô∏è `vision_therapy_cv/`

This module simulates key therapy concepts such as **per-eye occlusion, blur, and
contrast modulation** using a live camera or video input. It follows the same
system-level principles as the hardware path: **safety bounds, staged control,
telemetry, and reproducible logging**.

### Why this module exists
- Hardware lenses are expensive and not always available during early research
- Software simulation allows faster iteration and validation
- Enables test automation, data analysis, and ML experimentation
- Keeps the project moving while preserving architectural intent

### What it supports (current stage)
- JSON-based therapy profiles (occlusion cycles, blur, contrast)
- Left / right / binocular visual simulation
- Conservative safety limits on all effects
- Session-level CSV logging for validation and analysis

This module is **not a replacement** for the optical system.  
It is a **research and validation tool** that complements the ESP32-based hardware
pipeline and supports the long-term roadmap toward adaptive, closed-loop therapy.

‚û°Ô∏è See detailed usage and implementation:
[vision_therapy_cv/README.md](vision_therapy_cv/README.md)

---

---

## Quality & Testing
Standards‚Äëinspired (ISO 14971 risk thinking, IEC 62304/62366 mindset) ‚Äî **not certified**.
- **Levels:** unit (Python), integration (sensors/driver links), system (bench), usability (operator workflows)
- **Types:** functional, performance (latency/accuracy), reliability (repeatability), safety (slew limits, watchdog), data integrity
- **Gates:** entry/exit criteria per sprint; mandatory logs attached to PRs
- **CI:** lint (black, flake8), markdown lint, Arduino lint ‚Äî see `.github/workflows/ci.yml`

Docs: [`docs/URS.md`](docs/URS.md) ¬∑ [`docs/SRS.md`](docs/SRS.md) ¬∑ [`docs/RTM.md`](docs/RTM.md) ¬∑ [`docs/TEST_STRATEGY.md`](docs/TEST_STRATEGY.md) ¬∑ [`docs/TEST_CASES.md`](docs/TEST_CASES.md) ¬∑ [`docs/SAFETY_PROTOCOLS.md`](docs/SAFETY_PROTOCOLS.md)

---

**Optional ML module:** `host/pi/ml/` trains a logistic model on session data
to suggest small therapy adjustments. Safety clamps (duty/diopter) always
override ML outputs. See `docs/ML_OVERVIEW.md`.

---
## Quick Start
### Firmware (ESP32‚ÄëS3)
1. Install Arduino IDE + ESP32 core.
2. Wire LC shutter via DRV8833; sensors to I¬≤C.
3. Flash `firmware/esp32/main.cpp`; check serial output.

+## üîé For Supervisors/Admissions ‚Äî Start Here
+1. **Architecture:** `docs/ARCHITECTURE.md`
+2. **Roadmap (S1‚ÄìS6):** `docs/ROADMAP.md` with exit criteria
+3. **Safety & Risk:** `docs/SAFETY_PROTOCOLS.md`, `docs/RISK_REGISTER.md`
+4. **Testing approach:** `docs/TEST_STRATEGY.md`, `docs/TEST_CASES.md`
+5. **ML overview (optional):** `docs/ML_OVERVIEW.md` (guardrailed, CI-safe)
+6. **Proposal (short):** `docs/PROPOSAL_SHORT.pdf` ‚Äî 2 pages

+## Machine Learning (optional assist)
+The **ML module** in `host/pi/ml/` trains a small logistic model on session data to **suggest**
+therapy adjustments (e.g., occlusion duty). **Hard safety clamps** (duty/diopter) always override
+ML outputs; a rule-based fallback is used if the model is absent or confidence is low.
+See `docs/ML_OVERVIEW.md` and `docs/DATA_PRIVACY.md`.
+
+### ML quick demo (synthetic, CI-safe)
+```bash
+python host/pi/ml/make_synthetic.py
+python host/pi/ml/train.py
+pytest -q
+```

### Host (Pi/PC)
python3 -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt -r requirements-dev.txt
python host/pi/lens_controller.py   # update serial ports and driver commands

---

## Project Layout
```markdown
.
‚îú‚îÄ firmware/esp32/               # BLE + sensors + LC shutters
‚îú‚îÄ host/pi/                      # Lens driver control + policy + logs
‚îÇ  ‚îî‚îÄ ml/                        # Safe ML assist (training + inference)
‚îú‚îÄ apps/flutter_mobile/          # future BLE app
‚îú‚îÄ calibration/
‚îú‚îÄ tests/                        # pytest tests (incl. test_ml.py)
‚îú‚îÄ docs/                         # URS, SRS, RTM, Roadmap, Safety, ML, etc.
‚îú‚îÄ data/sessions/                # sample CSV logs (kept anon)
‚îú‚îÄ models/                       # saved model artifacts (joblib)
‚îú‚îÄ .github/workflows/ci.yml
‚îú‚îÄ README.md  CONTRIBUTING.md  CODE_OF_CONDUCT.md
‚îî‚îÄ LICENSE  CHANGELOG.md  .gitignore

```

---

## Roadmap
- **S1:** LC shutters + sensors + BLE telemetry (bench)
- **S2:** One tunable lens + calibration; Python control
- **S3:** Dual‚Äëeye integration; context policy; logging
- **S4:** Therapy modes; safety guards; reports
- **S5:** Wearable rig; comfort tuning; power mgmt
- **S6:** Optional eye tracking; analytics

Full details: [`docs/ROADMAP.md`](docs/ROADMAP.md)

---

## Hiring Manager Highlights
- **Traceability:** URS ‚Üí SRS ‚Üí RTM ‚Üí Test cases (audit‚Äëready thinking)
- **Safety mindset:** slew‚Äërate limiter, bounds, watchdog, session caps
- **Process:** CI with lint/tests; issue/PR templates; Conventional Commits
- **Systems thinking:** optics + embedded + host + data pipeline

---

## Contributing
See [`CONTRIBUTING.md`](CONTRIBUTING.md). Use **Conventional Commits** and PR template. Attach test logs (scope screenshots for LC drive, diopter ramps) when relevant.

---

## License
MIT ‚Äî see [`LICENSE`](LICENSE).

---

### GitHub Polish Checklist
- Repo topics: `amblyopia`, `tunable-lens`, `embedded`, `esp32`, `python`, `vision-science`, `qa-testing`
- Social preview: upload `assets/social-preview.png` (1200√ó630)
- Pin this repo; add it to CV/LinkedIn
- CI badge already points to `https://github.com/AsadRahu60/eye-adaptive-lens/actions`
